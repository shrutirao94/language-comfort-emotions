{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c2b419-4dac-43a8-a549-d876851ae387",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "1. Scaled representation of : `pos`, `neg`, `neutral` [done]\n",
    "2. Aspect-based analysis: which particular aspects or features are mentioned in a positive, neutral, or negative way. []\n",
    "3. Semantic Clustering []\n",
    "4. Feature Analysis []\n",
    "5. Aspect Similaarity co-occurance\n",
    "6. Emotion aspect co-occurance\n",
    "\n",
    "   ======\n",
    "\n",
    "1. Overall sentiment [done]\n",
    "2. Sentiment by floor and space [done]\n",
    "3. Sentiment by type of space i.e. group vs individual [done]\n",
    "4. Sentiment by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e270e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "[2023-06-09 17:05:25] (2.3.1) \u001b[31mPyABSA(2.3.1): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.16.27\n",
      "\n",
      "[New Feature] Aspect Sentiment Triplet Extraction since v2.1.0 (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_sentiment_triplet_extration)\n",
      "[New Feature] Aspect CategoryOpinion Sentiment Quadruple Extraction since v2.2.0 (https://github.com/yangheng95/PyABSA/tree/v2/examples-v2/aspect_opinion_sentiment_category_extraction)\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.corpus import wordnet\n",
    "# from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer \n",
    "\n",
    "# import stanfordnlp\n",
    "\n",
    "from transformers import pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from pyabsa import ATEPCCheckpointManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a139ac2b-96a5-41ab-b3e7-3ac03ef83cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "# stanfordnlp.download('en')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e1a302-4814-4aa5-a11d-83885a45568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_emo=['occupation', 'usage', 'recruitment', 'comfort']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c48db1-07a4-4f38-bc32-00271a416399",
   "metadata": {},
   "source": [
    "# Students at LAB42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b647ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emo_sl42 = pd.read_csv('data/lab42_cleaned_data.csv', index_col=0).drop(columns = drop_col_emo, axis=1).dropna(subset=['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d96c5df-3423-4332-a759-7a19ac197ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floor</th>\n",
       "      <th>ground-floor</th>\n",
       "      <th>1-floor</th>\n",
       "      <th>2-floor</th>\n",
       "      <th>3-floor</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I always feel a bit zen when I am here. It’s q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cold, a bit down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6th Floor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hungry, a bit cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ground floor</td>\n",
       "      <td>Library learning room</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stressed about my exams but I am happy in this...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          floor           ground-floor 1-floor 2-floor 3-floor  \\\n",
       "1           NaN                    NaN     NaN     NaN     NaN   \n",
       "2           NaN                    NaN     NaN     NaN     NaN   \n",
       "3           NaN                    NaN     NaN     NaN     NaN   \n",
       "4     6th Floor                    NaN     NaN     NaN     NaN   \n",
       "5  Ground floor  Library learning room     NaN     NaN     NaN   \n",
       "\n",
       "                                             emotion  \n",
       "1  I always feel a bit zen when I am here. It’s q...  \n",
       "2                                   Cold, a bit down  \n",
       "3                                               Calm  \n",
       "4                                 Hungry, a bit cold  \n",
       "5  Stressed about my exams but I am happy in this...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_sl42.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b42b309-3625-4c87-87c9-44d961ba66a2",
   "metadata": {},
   "source": [
    "## LLM-based Overall Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805e89d-3f41-41c0-9bfe-ceb8c725c540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=MODEL, tokenizer=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0f444-081a-4636-8cdc-6b25b45bebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(sentence):\n",
    "    return sentiment_task(sentence, top_k=3)\n",
    "\n",
    "def assign_scores(idx):\n",
    "    emo_sl42.at[idx, 'positive'] = next(item for item in emo_sl42['senti'][idx] if item['label'] == 'positive')['score']\n",
    "    emo_sl42.at[idx, 'negative'] = next(item for item in emo_sl42['senti'][idx] if item['label'] == 'negative')['score']\n",
    "    emo_sl42.at[idx, 'neutral'] = next(item for item in emo_sl42['senti'][idx] if item['label'] == 'neutral')['score']\n",
    "\n",
    "def plot_sentiment_analysis(df, label):\n",
    "    sns.countplot(y=df[label + \"_label\"], \n",
    "                  palette=['#b2d8d8',\"#008080\", '#db3d13'],\n",
    "                  order=[\"positive\", \"negative\", \"neutral\"])\n",
    "    plt.ylabel(\"Overall Sentiment for Emotion Responses\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.savefig('plots/sentiment-analysis/students-lab42/' + label + '-llm-sentiment-count.jpg',\n",
    "                dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb126b3-cf3f-4ed8-8a4c-71ee41c5fe07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Calculate sentiment analysis on each emotion statement:\n",
    "emo_sl42['senti'] = emo_sl42['emotion'].apply(sentiment_analysis)\n",
    "\n",
    "# 2. Sort Sentiment Scores into Independent Columns\n",
    "for idx in emo_sl42.index:\n",
    "    assign_scores(idx)\n",
    "\n",
    "# 3. Drop Unecessary Columns\n",
    "emo_sl42 = emo_sl42.drop(columns=['senti'])\n",
    "\n",
    "# 4. Calculate the dominant overall sentiment of the response\n",
    "emo_sl42['emo_label'] = emo_sl42[['positive', 'negative', 'neutral']].idxmax(axis=1)\n",
    "\n",
    "# 5. Plot the overall sentiments distribution\n",
    "plot_sentiment_analysis(emo_sl42, 'emo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947d9a0-3e1f-4340-9805-86d53ce64f09",
   "metadata": {},
   "source": [
    "## Lexicon-based Analysis using VADER\n",
    "Here we are interested in the rule-based analysis. The compound score is computed by summing the \n",
    "valence scores of each word in the lexicon, adjusted according to the rules, and then normalized \n",
    "to be between -1 (most extreme negative) and +1 (most extreme positive). \n",
    "It is a 'normalized, weighted composite score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a48ac-8a2d-4275-ab5c-dfa460a45280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_lexicon_analysis(df, label):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df[label + '-composite-score'] = df[label].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])\n",
    "    \n",
    "    return df \n",
    "\n",
    "def plot_lexicon_analysis(df, label):\n",
    "    sns.boxplot(x='floor', y='emotion-composite-score', data=df)\n",
    "    plt.xlabel(\"Floor\")\n",
    "    plt.ylabel(\"Lexicon-based Normalised Weighted Composite Score \\n (1 = Most Positive; 0 = Neutral; -1 = Most Negative)\")\n",
    "    plt.tick_params(bottom=False)\n",
    "    plt.axhline(0, ls='--', c = 'grey')\n",
    "    plt.savefig('plots/sentiment-analysis/students-lab42/' +\n",
    "                label +\n",
    "                '-vader-lexicon-composite.jpg',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    sns.displot(x='emotion-composite-score', kde=True, \n",
    "                height=4,\n",
    "                aspect=1.5,\n",
    "                data=emo_sl42)\n",
    "    plt.xlabel(\"Lexicon-Based Normalised Weighted Composite Scores for Sentiments \\n (1 = Most Positive; 0 = Neutral; -1 = Most Negative)\")\n",
    "    plt.tick_params(bottom=False)\n",
    "    plt.axhline(0, ls='--', c = 'grey')\n",
    "    plt.savefig('plots/sentiment-analysis/students-lab42/' +\n",
    "                label +\n",
    "                '-distribution-lexicon-composite.jpg',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    sns.displot(x='emotion-composite-score', y='emo_label',\n",
    "                binwidth=(.2, .1),\n",
    "                height=4,\n",
    "                aspect=1.5,\n",
    "                data=emo_sl42)\n",
    "    plt.xlabel(\"Lexicon-Based Normalised Weighted Composite Scores for Sentiments \\n (1 = Most Positive; 0 = Neutral; -1 = Most Negative)\")\n",
    "    plt.ylabel(\"LLM Generated Sentiment Labels\")\n",
    "    plt.tick_params(bottom=False)\n",
    "    plt.savefig('plots/sentiment-analysis/students-lab42/' +\n",
    "                label +\n",
    "                '-vader-vs-lexicon-composite.jpg',\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "\n",
    "def plot_sentiment_analysis_spaces(df, label):\n",
    "    df = df.where(df[\"space-type\"] != \"\").dropna(how=\"all\")\n",
    "    f = plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='space-type', y='compound', width=0.5,\n",
    " data=df)\n",
    "    plt.xlabel(\"Space Type\")\n",
    "    plt.ylabel(\"Sentiment Value \\n (1 = Most Positive; 0 = Neutral; -1 = Most Negative)\")\n",
    "    plt.tick_params(bottom=False)\n",
    "    plt.axhline(0, ls='--', c = 'grey')\n",
    "    plt.savefig('plots/lab42-' + label + '-space-wise-sentiment-distribution.jpg',\n",
    "                dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05b071-15eb-43c8-b4c2-3e692ae5411a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emo_sl42 = vader_lexicon_analysis(emo_sl42, 'emotion')\n",
    "plot_lexicon_analysis(emo_sl42, 'emotion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40769e0-9f27-4273-ab44-e7f8bbae766c",
   "metadata": {},
   "source": [
    "## Scale data to scores between -1 and 1\n",
    "Polarity score in the range of -1 to -0.5 typically indicates negative sentiment\n",
    "Polarity score greater than -0.5 and less than +0.5 typically indicates neutral sentiment\n",
    "Polarity score in the range of +0.5 to 1 typically indicates positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52582e49-b5f5-4cc7-a157-f35cfda248f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_emotion_values():\n",
    "    labels = ['positive', 'negative', 'neutral']\n",
    "    scales = [(0.5, 1.0), (-1.0, -0.5), (-0.5, 0.5)]\n",
    "    emo_sl42['scaled_scores'] = 0\n",
    "    \n",
    "    for label, scale in zip(labels, scales):\n",
    "        values = np.array(emo_sl42[label][emo_sl42['emo_label'] == label]).reshape(-1,1)\n",
    "        idx = emo_sl42.index[emo_sl42['emo_label'] == label].to_list()\n",
    "        scaled_values = minmax_scaler(scale, values, idx)\n",
    "        emo_sl42.loc[idx,'scaled_scores'] = scaled_values\n",
    "    \n",
    "    return emo_sl42\n",
    "\n",
    "\n",
    "def minmax_scaler(scale, values, idx):\n",
    "    scaler = MinMaxScaler(feature_range = scale)\n",
    "    scaled_values = pd.Series(scaler.fit_transform(values).flatten()).set_axis(idx)\n",
    "    \n",
    "    return scaled_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453f1f5-f674-4298-9396-ec1befa53598",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_sl42 = scale_emotion_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da4ba8-7eea-4f12-86c1-88e4e6618d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = ['Round tables by the three plants (across wooden staircase)',\n",
    "                        'Next to the lockers',\n",
    "                        'Study corner next to the plant wall',\n",
    "                        'Yellow/white chairs & tables (besides the wooden staircase)',\n",
    "                        'Tables on the landing (with wooden floor) accessible by the black staircase',\n",
    "                        'Green group study tables (between a row of plants and railing)',\n",
    "                        'Group tables by the stairs',\n",
    "                        'Open lounge area',\n",
    "                        'Near the printer',\n",
    "                        'Round tables by the coffee machine']\n",
    "\n",
    "individual =  ['Library learning room',\n",
    "                             'Green chairs by the entrance',\n",
    "                             'Partly covered green chairs (along glass wall)']\n",
    "\n",
    "unsure = [\"Unsure\"]\n",
    "\n",
    "def assign_types_to_spaces(space):\n",
    "    if space in group:\n",
    "        return \"group\"\n",
    "    if space in individual:\n",
    "        return \"individual\"\n",
    "    if space in unsure:\n",
    "        return \"unsure\"\n",
    "    \n",
    "def merge_spaces(df):\n",
    "    df[\"space-type\"] = df[\"space-ground-floor\"] + df[\"space-1-floor\"] + df[\"space-2-floor\"] + df[\"space-3-floor\"]\n",
    "    df = df.drop(columns =[\"space-ground-floor\", \"space-1-floor\", \"space-2-floor\", \"space-3-floor\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_group_solo_space_labels(df):\n",
    "    spaces = [\"ground-floor\", \"1-floor\", \"2-floor\", \"3-floor\"]\n",
    "    \n",
    "    for space in spaces:\n",
    "        df[\"space-\" + space] = df[space].apply(lambda space: assign_types_to_spaces(space)).fillna(\"\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_sentiment_analysis_spaces(df, label):\n",
    "    df = df.where(df[\"space-type\"] != \"\").dropna(how=\"all\")\n",
    "    f = plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='space-type', y='scaled_scores',\n",
    "                width=0.5,\n",
    "                data=df)\n",
    "    plt.xlabel(\"Space Type\")\n",
    "    plt.ylabel(\"Sentiment Value \\n (1 = Most Positive; 0 = Neutral; -1 = Most Negative)\")\n",
    "    plt.tick_params(bottom=False)\n",
    "    plt.axhline(0, ls='--', c = 'grey')\n",
    "    plt.savefig('plots/lab42-' + label + '-space-wise-sentiment-distribution.jpg',\n",
    "                dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240769a1-5be4-4c2e-affe-3baa007832b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_group_solo_space_labels(emo_sl42)\n",
    "df = merge_spaces(df)\n",
    "plot_sentiment_analysis_spaces(df, 'emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fd417-4d0a-4ebc-820b-a21139d6557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overview_sentiment_analysis_spaces(df, label):\n",
    "    df = df.where(df[\"space-type\"] != \"\").dropna(how=\"all\")\n",
    "    f = plt.figure(figsize=(10, 6))\n",
    "    sns.catplot(data=df, \n",
    "                x=\"floor\", y='scaled_scores',\n",
    "                hue=\"emo_label\",\n",
    "                col=\"space-type\",\n",
    "                kind=\"swarm\" )\n",
    "    plt.xlabel(\"Floor\")\n",
    "    plt.ylabel(\"Scaled Sentiment Value \\n (1 = Most Positive; 0 = Neutral; -1 = Most Negative)\")\n",
    "    plt.tick_params(bottom=False)\n",
    "    plt.savefig('plots/lab42-' + label + 'floor-space-wise-sentiment-distribution.jpg',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "# sns.countplot(y=emo_sl42[\"emo_label\"], palette=['#b2d8d8',\"#008080\", '#db3d13'],order=[\"positive\", \"negative\", \"neutral\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48387a8-852f-4800-bc70-4381324b9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overview_sentiment_analysis_spaces(emo_sl42, \"emo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9b550-9851-4820-8d77-b37e64c982db",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_sl42['dominant_emo_val'] = emo_sl42[['positive', 'negative', 'neutral']].max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e56caf-af30-4394-883f-e1781ee56903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='emo_label', y='dominant_emo_val', hue=\"space-type\",\n",
    "            kind=\"bar\", errorbar=None, data=emo_sl42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68eb827-4ef8-4bc4-80f1-4cfe84ba8043",
   "metadata": {},
   "source": [
    "## Aspect-Based Sentiment Analysis\n",
    "\n",
    "maybe train your own model: https://github.com/shwe24/Aspect-Based-Sentiment-Classification/blob/main/Aspect_Extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e38301-db7d-49ef-a947-1b4f0e891aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = emo_sl42.emotion[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9520f6-9e4e-4cea-87bd-86b1719f5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ea4fd-78b7-4f9e-b752-fb22da9540e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf6f6b-001d-4d7c-b2db-d98f3a25419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Aspect-Based Sentiment Analysis model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48277ac-75b0-448d-aee3-3d92aef76efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'It’s quiet and not noisy. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b64bc-41d3-497c-a5bb-36c8a9c70a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABSA of \"food\"\n",
    "aspect = \"noisy\"\n",
    "inputs = absa_tokenizer(f\"[CLS] {txt} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "  print(f\"Label {label}: {prob}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895676f-2580-40bf-837e-6a5c16fb5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall sentiment of the sentence\n",
    "sentiment = sentiment_task(txt)[0]\n",
    "print(f\"Overall sentiment: {sentiment['label']} with score {sentiment['score']}\")\n",
    "# Overall sentiment: Negative with score 0.7706006765365601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dadd32-6227-4ca5-bfbe-abbe3541ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = emo_sl42.emotion[148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957744a-0153-43b5-9bb5-dd82252cd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b033d0-d83e-4446-9dd0-7bd5dcf62a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda8152-5c4a-4824-aec9-c230e5b733b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "emo_aspect_terms = []\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "for review in nlp.pipe(emo_sl42.emotion):\n",
    "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'CCONJ']\n",
    "    emo_aspect_terms.append(' '.join(chunks))\n",
    "emo_sl42['emo_aspect_terms'] = emo_aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525e16b-787b-432c-a69c-665e4d4f638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_sl42.emo_aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70861a60-fccc-41b9-852d-94b947a56144",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2f6660-d9c9-4780-950d-0665b800d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f8dd75-2de9-459d-b574-5d14c3da99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"I’m a little cold, but otherwise calm and comfortable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa41914-6f44-40a4-8723-23a654b29802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON PRP nsubj X True True\n",
      "’m VERB VBP ROOT ’x False True\n",
      "a DET DT det x True True\n",
      "little ADJ JJ amod xxxx True False\n",
      "cold ADJ JJ acomp xxxx True False\n",
      ", PUNCT , punct , False False\n",
      "but CCONJ CC cc xxx True True\n",
      "otherwise ADV RB advmod xxxx True True\n",
      "calm ADJ JJ conj xxxx True False\n",
      "and CCONJ CC cc xxx True True\n",
      "comfortable ADJ JJ conj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(txt)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba13d31-a93b-44c6-8792-403db00aadc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193290520773312886 demo 0 1 cold\n",
      "2193290520773312886 demo 4 5 calm\n",
      "2193290520773312886 demo 6 7 comfortable\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "patterns = [\n",
    "    [{'POS':'ADJ'}],\n",
    "    ]\n",
    "matcher.add(\"demo\", patterns)\n",
    "\n",
    "doc = nlp(txt)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a795e7-cc55-4708-b1b5-6dd7bc601345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "’m VERB\n",
      "a DET\n",
      "little ADJ\n",
      "cold ADJ\n",
      ", PUNCT\n",
      "but CCONJ\n",
      "otherwise ADV\n",
      "a DET\n",
      "bit NOUN\n",
      "calm ADJ\n",
      "and CCONJ\n",
      "comfortable ADJ\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "txt = \"I’m a little cold, but otherwise a bit calm and comfortable\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(txt)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45fb5085-2b94-47f9-a7a9-b968cb0fcc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "\n",
    "pattern = [\n",
    "  {\n",
    "    \"RIGHT_ID\": \"target\",\n",
    "    \"RIGHT_ATTRS\": {\"POS\": \"ADJ\"}\n",
    "  },\n",
    "  # founded -> subject\n",
    "  {\n",
    "    \"LEFT_ID\": \"target\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"modifier\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"amod\", \"nummod\"]}}\n",
    "  },\n",
    "]\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "matcher.add(\"FOUNDED\", [pattern])\n",
    "txt = \"I’m a little cold, but otherwise a bit calm and comfortable\"\n",
    "doc = nlp(txt)\n",
    "for match_id, (target, modifier) in matcher(doc):\n",
    "    print(doc[modifier], doc[target], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c3c378b-0eb3-48ff-84cc-a53d72590621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_adj_pairs = {}\n",
    "for chunk in doc.ad:\n",
    "    adj = []\n",
    "    noun = \"\"\n",
    "    for tok in chunk:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            noun = tok.text\n",
    "        if tok.pos_ == \"ADJ\" or tok.pos_ == \"CCONJ\":\n",
    "            adj.append(tok.text)\n",
    "    if noun:\n",
    "        noun_adj_pairs.update({noun:\" \".join(adj)})\n",
    "\n",
    "noun_adj_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbab16b-90b7-4ddb-b589-f966159ee207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
